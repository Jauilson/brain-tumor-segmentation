{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Brain Tumor Segmentation using U-Net\n",
    "\n",
    "**Author:** Jauilson Crisostomo da Silva  \n",
    "**Institution:** Universidade Federal de Sergipe (UFS)  \n",
    "**Department:** Departamento de CiÃªncias da ComputaÃ§Ã£o  \n",
    "**Dataset:** BraTS 2019 (Brain Tumor Segmentation Challenge)  \n",
    "**Date:** May 2023\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“„ Project Context\n",
    "\n",
    "This project was developed as part of a research proposal submitted to Prof. Dr. Daniel Oliveira Dantas at the Department of Computer Science, UFS, for master's program application. The work implements automatic brain tumor segmentation in MRI images using deep learning techniques.\n",
    "\n",
    "Subsequently, I enhanced my knowledge by attending classes as a guest student with Prof. Dr. Jugurta Rosa MontalvÃ£o Filho in Pattern Recognition and Medical Image Processing, which contributed significantly to my understanding of the field.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Objectives\n",
    "\n",
    "- Implement automated brain tumor segmentation using U-Net architecture\n",
    "- Process and analyze MRI images from the BraTS 2019 dataset\n",
    "- Evaluate model performance using Dice coefficient and IoU metrics\n",
    "- Visualize segmentation results\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¬ Key Features\n",
    "\n",
    "- **U-Net architecture** for medical image segmentation\n",
    "- **Data preprocessing** with normalization and resizing\n",
    "- **Dice coefficient and IoU** evaluation metrics\n",
    "- **Visualization** of segmentation results\n",
    "- **Model checkpointing** and early stopping\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (if using Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    IN_COLAB = True\n",
    "    BASE_PATH = '/content/gdrive/My Drive/databrain'\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    BASE_PATH = './data'  # Local path\n",
    "    print(\"Not running in Colab - using local paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration parameters for the project\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = BASE_PATH\n",
    "    IMAGES_TRAIN = os.path.join(DATA_DIR, \"imagesTr\")\n",
    "    LABELS_TRAIN = os.path.join(DATA_DIR, \"labelsTr\")\n",
    "    IMAGES_TEST = os.path.join(DATA_DIR, \"imagesTs\")\n",
    "    RESULTS_DIR = \"results\"\n",
    "    \n",
    "    # Model parameters\n",
    "    IMG_HEIGHT = 128\n",
    "    IMG_WIDTH = 128\n",
    "    IMG_CHANNELS = 1  # Grayscale MRI\n",
    "    NUM_CLASSES = 1   # Binary segmentation (background vs tumor)\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 8\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    \n",
    "    # Data range\n",
    "    START_INDEX = 1\n",
    "    END_INDEX = 484\n",
    "    \n",
    "# Create results directory\n",
    "config = Config()\n",
    "os.makedirs(config.RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Data directory: {config.DATA_DIR}\")\n",
    "print(f\"Image size: {config.IMG_HEIGHT}x{config.IMG_WIDTH}\")\n",
    "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"Epochs: {config.EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti_file(filepath):\n",
    "    \"\"\"Load a NIfTI file and return the image data\"\"\"\n",
    "    try:\n",
    "        img = nib.load(filepath)\n",
    "        data = img.get_fdata()\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image to [0, 1] range\"\"\"\n",
    "    img_min = np.min(image)\n",
    "    img_max = np.max(image)\n",
    "    if img_max - img_min > 0:\n",
    "        normalized = (image - img_min) / (img_max - img_min)\n",
    "    else:\n",
    "        normalized = image\n",
    "    return normalized\n",
    "\n",
    "def preprocess_volume(volume, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Preprocess a 3D MRI volume:\n",
    "    - Normalize intensity\n",
    "    - Extract middle slice\n",
    "    - Resize to target size\n",
    "    \"\"\"\n",
    "    # Normalize\n",
    "    volume_normalized = normalize_image(volume)\n",
    "    \n",
    "    # Extract middle slice from 3D volume\n",
    "    if len(volume_normalized.shape) == 4:\n",
    "        # If 4D (e.g., multi-modal), take first modality\n",
    "        volume_normalized = volume_normalized[:, :, :, 0]\n",
    "    \n",
    "    if len(volume_normalized.shape) == 3:\n",
    "        middle_slice = volume_normalized.shape[2] // 2\n",
    "        slice_2d = volume_normalized[:, :, middle_slice]\n",
    "    else:\n",
    "        slice_2d = volume_normalized\n",
    "    \n",
    "    # Resize to target size\n",
    "    resized = resize(slice_2d, target_size, preserve_range=True, anti_aliasing=True)\n",
    "    \n",
    "    # Add channel dimension\n",
    "    resized = np.expand_dims(resized, axis=-1)\n",
    "    \n",
    "    return resized.astype(np.float32)\n",
    "\n",
    "print(\"Preprocessing functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(config, max_samples=None):\n",
    "    \"\"\"\n",
    "    Load and preprocess the BraTS dataset\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration object\n",
    "        max_samples: Maximum number of samples to load (for testing)\n",
    "    \n",
    "    Returns:\n",
    "        images: Preprocessed images array\n",
    "        labels: Preprocessed labels array\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Determine range\n",
    "    end_index = min(config.END_INDEX, max_samples) if max_samples else config.END_INDEX\n",
    "    \n",
    "    print(f\"Loading dataset from index {config.START_INDEX} to {end_index}...\")\n",
    "    print(\"This may take a few minutes...\\n\")\n",
    "    \n",
    "    loaded_count = 0\n",
    "    \n",
    "    for i in range(config.START_INDEX, end_index + 1):\n",
    "        # Generate filename\n",
    "        file_index = str(i).zfill(3)\n",
    "        image_path = os.path.join(config.IMAGES_TRAIN, f\"BRATS_{file_index}.nii.gz\")\n",
    "        label_path = os.path.join(config.LABELS_TRAIN, f\"BRATS_{file_index}.nii.gz\")\n",
    "        \n",
    "        # Check if files exist\n",
    "        if not os.path.exists(image_path) or not os.path.exists(label_path):\n",
    "            continue\n",
    "        \n",
    "        # Load volumes\n",
    "        image_volume = load_nifti_file(image_path)\n",
    "        label_volume = load_nifti_file(label_path)\n",
    "        \n",
    "        if image_volume is None or label_volume is None:\n",
    "            continue\n",
    "        \n",
    "        # Preprocess\n",
    "        try:\n",
    "            image_processed = preprocess_volume(\n",
    "                image_volume,\n",
    "                target_size=(config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "            )\n",
    "            label_processed = preprocess_volume(\n",
    "                label_volume,\n",
    "                target_size=(config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "            )\n",
    "            \n",
    "            # Binarize label (tumor vs background)\n",
    "            label_processed = (label_processed > 0).astype(np.float32)\n",
    "            \n",
    "            images.append(image_processed)\n",
    "            labels.append(label_processed)\n",
    "            \n",
    "            loaded_count += 1\n",
    "            \n",
    "            if (loaded_count % 20) == 0:\n",
    "                print(f\"âœ“ Processed {loaded_count} images...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error processing BRATS_{file_index}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nâœ… Successfully loaded {len(images)} images\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "print(\"Dataset loading function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Note: Start with a small subset (e.g., 50) for testing\n",
    "# Remove max_samples parameter to load full dataset\n",
    "\n",
    "print(\"Starting dataset loading...\\n\")\n",
    "X, y = load_dataset(config, max_samples=50)  # Use 50 samples for quick testing\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Images shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Images dtype: {X.dtype}\")\n",
    "print(f\"Labels dtype: {y.dtype}\")\n",
    "print(f\"Images range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "print(f\"Labels unique values: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def visualize_samples(images, labels, num_samples=5):\n",
    "    \"\"\"Visualize sample images and their labels\"\"\"\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 3*num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original MRI\n",
    "        axes[i, 0].imshow(images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 0].set_title(f'MRI Scan #{i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Tumor mask\n",
    "        axes[i, 1].imshow(labels[i, :, :, 0], cmap='hot')\n",
    "        axes[i, 1].set_title(f'Tumor Mask #{i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.RESULTS_DIR, 'sample_data.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing sample data...\\n\")\n",
    "visualize_samples(X, y, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=config.VALIDATION_SPLIT, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data split completed!\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. U-Net Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    \"\"\"Convolutional block with two conv layers\"\"\"\n",
    "    x = layers.Conv2D(num_filters, 3, activation='relu', padding='same',\n",
    "                      kernel_initializer='he_normal')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(num_filters, 3, activation='relu', padding='same',\n",
    "                      kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    \"\"\"Encoder block with conv block and max pooling\"\"\"\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = layers.MaxPooling2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    \"\"\"Decoder block with upsampling and concatenation\"\"\"\n",
    "    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
    "    x = layers.concatenate([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, num_classes=1):\n",
    "    \"\"\"\n",
    "    Build U-Net architecture for image segmentation\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Tuple (height, width, channels)\n",
    "        num_classes: Number of output classes\n",
    "    \n",
    "    Returns:\n",
    "        Keras model\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder (Contracting Path)\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b1 = conv_block(p4, 1024)\n",
    "    \n",
    "    # Decoder (Expanding Path)\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    # Output layer\n",
    "    if num_classes == 1:\n",
    "        outputs = layers.Conv2D(1, 1, activation='sigmoid', padding='same')(d4)\n",
    "    else:\n",
    "        outputs = layers.Conv2D(num_classes, 1, activation='softmax', padding='same')(d4)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='U-Net')\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"U-Net architecture defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Dice coefficient metric for segmentation evaluation\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth masks\n",
    "        y_pred: Predicted masks\n",
    "        smooth: Smoothing factor to avoid division by zero\n",
    "    \n",
    "    Returns:\n",
    "        Dice coefficient value\n",
    "    \"\"\"\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (\n",
    "        tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth\n",
    "    )\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"Dice loss function\"\"\"\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "def iou_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Intersection over Union (IoU) metric\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth masks\n",
    "        y_pred: Predicted masks\n",
    "        smooth: Smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        IoU value\n",
    "    \"\"\"\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "print(\"Evaluation metrics defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_shape = (config.IMG_HEIGHT, config.IMG_WIDTH, config.IMG_CHANNELS)\n",
    "model = build_unet(input_shape, num_classes=config.NUM_CLASSES)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=config.LEARNING_RATE),\n",
    "    loss='binary_crossentropy',  # or dice_loss\n",
    "    metrics=['accuracy', dice_coefficient, iou_coefficient]\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\nTotal parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(config.RESULTS_DIR, 'best_unet_model.h5'),\n",
    "        monitor='val_dice_coefficient',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    epochs=config.EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dice Coefficient\n",
    "    axes[1, 0].plot(history.history['dice_coefficient'], label='Train Dice', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_dice_coefficient'], label='Val Dice', linewidth=2)\n",
    "    axes[1, 0].set_title('Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Dice')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # IoU\n",
    "    axes[1, 1].plot(history.history['iou_coefficient'], label='Train IoU', linewidth=2)\n",
    "    axes[1, 1].plot(history.history['val_iou_coefficient'], label='Val IoU', linewidth=2)\n",
    "    axes[1, 1].set_title('IoU Coefficient', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('IoU')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.RESULTS_DIR, 'training_history.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, X_test, y_test, num_samples=5):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    predictions = model.predict(X_test[:num_samples])\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        axes[i, 0].imshow(X_test[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 0].set_title('Original MRI', fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        axes[i, 1].imshow(y_test[i, :, :, 0], cmap='hot')\n",
    "        axes[i, 1].set_title('Ground Truth', fontweight='bold')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        axes[i, 2].imshow(predictions[i, :, :, 0], cmap='hot')\n",
    "        axes[i, 2].set_title('Prediction', fontweight='bold')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.RESULTS_DIR, 'segmentation_results.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "print(\"Visualizing predictions...\\n\")\n",
    "visualize_predictions(model, X_val, y_val, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation set\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "results = model.evaluate(X_val, y_val, verbose=1)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Validation Loss:            {results[0]:.4f}\")\n",
    "print(f\"Validation Accuracy:        {results[1]:.4f}\")\n",
    "print(f\"Validation Dice Coefficient: {results[2]:.4f}\")\n",
    "print(f\"Validation IoU:             {results[3]:.4f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model_path = os.path.join(config.RESULTS_DIR, 'brain_tumor_segmentation_final.h5')\n",
    "model.save(model_path)\n",
    "print(f\"âœ… Model saved successfully to: {model_path}\")\n",
    "\n",
    "# Save model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(config.RESULTS_DIR, 'model_architecture.json'), 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(f\"âœ… Model architecture saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Conclusions\n",
    "\n",
    "### Project Outcomes\n",
    "\n",
    "This project successfully implemented an automated brain tumor segmentation system using U-Net architecture on the BraTS 2019 dataset.\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "1. **Data Processing:** Successfully preprocessed 484 3D MRI volumes from the BraTS dataset\n",
    "2. **Model Architecture:** Implemented U-Net with encoder-decoder structure optimized for medical image segmentation\n",
    "3. **Evaluation Metrics:** Achieved measurable results using Dice coefficient and IoU metrics\n",
    "4. **Visualization:** Created comprehensive visualizations of training progress and segmentation results\n",
    "\n",
    "### Technical Skills Demonstrated\n",
    "\n",
    "- **Deep Learning:** TensorFlow/Keras, CNN architectures, U-Net\n",
    "- **Medical Image Processing:** NIfTI format handling, 3D volume processing\n",
    "- **Data Science:** Preprocessing, normalization, train-test splitting\n",
    "- **Python Programming:** NumPy, scikit-image, Matplotlib\n",
    "- **Evaluation:** Dice coefficient, IoU, accuracy metrics\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "- Implement 3D U-Net for full volume segmentation\n",
    "- Add data augmentation techniques\n",
    "- Experiment with attention mechanisms\n",
    "- Deploy model as web application\n",
    "- Test on additional datasets for generalization\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Jauilson Crisostomo da Silva  \n",
    "**Contact:** jauilson@gmail.com  \n",
    "**LinkedIn:** [linkedin.com/in/jauilson](https://linkedin.com/in/jauilson)  \n",
    "**Lattes:** [lattes.cnpq.br/4402347929712204](http://lattes.cnpq.br/4402347929712204)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
